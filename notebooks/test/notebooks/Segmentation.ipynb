{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae71d45b-b0cf-421f-8510-6f622a89e1b6",
   "metadata": {},
   "source": [
    "<h1>Segmentation script</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f670e-ad3b-4e84-965e-6d5e5d5809da",
   "metadata": {},
   "source": [
    "<h2>Importing packages</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76164db-50ce-4e20-931f-e4e33fbb7834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported all packages\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "!pip install roboflow\n",
    "!pip install folium\n",
    "!pip install PyQt5\n",
    "from IPython.display import display, Image\n",
    "from IPython import display\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "from shapely.geometry import Polygon\n",
    "import pandas as pd\n",
    "import folium\n",
    "display.clear_output()\n",
    "print(\"Successfully imported all packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19694021-5a2f-4fa0-90ee-74327c319fae",
   "metadata": {},
   "source": [
    "<h2>Importing a trained model from Roboflow</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe6ba52-3805-4fd9-8b10-e4b806797b71",
   "metadata": {},
   "source": [
    "<h3>Create a Roboflow Project:</h3>\n",
    "Sign in to your Roboflow account and create a new project, selecting \"Instance Segmentation\" as the task type.\n",
    "\n",
    "<h3>Annotate your Data:</h3>\n",
    "Upload your images and use the Roboflow annotation tool to label each object instance.\n",
    "\n",
    "<h3>Splitting and Downloading the Dataset:</h3>\n",
    "Once annotations are complete, split your dataset into training, validation, and test sets using Roboflow's splitting tool. Then, navigate to the \"Versions\" tab, select the desired version, click \"Export Dataset,\" choose \"COCO Segmentation\" format, and click \"Show Download Code\" to generate a code snippet containing the download link.\n",
    "\n",
    "<h3>Paste the Download Code:</h3>\n",
    "Copy the entire code snippet provided by Roboflow and paste it into the designated code block below in your JupyterLab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60c0e1e-1b07-43e1-af01-9ed81c49a149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted data from roboflow\n"
     ]
    }
   ],
   "source": [
    "# Paste your snippet here\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"YgqaFYQYMXIDYOCYoY2O\") \n",
    "project = rf.workspace(\"footage\").project(\"seafloor-segmentation\") \n",
    "model = project.version(\"1\").model\n",
    "display.clear_output()\n",
    "print(\"Successfully extracted data from roboflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13a851-8ff7-4ff0-b0fd-bed138cc1ff9",
   "metadata": {},
   "source": [
    "<h2>Prediction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906a8416-badc-4751-b474-4f021542c089",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 107\u001b[0m\n\u001b[1;32m    103\u001b[0m         labeled_prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(filepath, confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)  \u001b[38;5;66;03m# Perform prediction with labels and save the result, set confidence threshold here.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m         output_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(filename)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_prediction.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Generate the output image path for labeled prediction\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m         \u001b[43mlabeled_prediction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_image_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Save the labeled prediction result to an image file\u001b[39;00m\n\u001b[1;32m    109\u001b[0m         display\u001b[38;5;241m.\u001b[39mclear_output()  \u001b[38;5;66;03m# Clear the output\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_area_percentages\u001b[39m(output_dir):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/roboflow/util/prediction.py:334\u001b[0m, in \u001b[0;36mPredictionGroup.save\u001b[0;34m(self, output_path, stroke)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, stroke\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;66;03m# Load image based on image path as an array\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     stroke_color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;66;03m# Iterate through predictions and add prediction to image\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/roboflow/util/prediction.py:330\u001b[0m, in \u001b[0;36mPredictionGroup.__load_image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Return array with image info of local image\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_image_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_output_dir(base_dir):\n",
    "    \"\"\"\n",
    "    Create an output directory if it doesn't exist.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory path.\n",
    "\n",
    "    Returns:\n",
    "        str: The created output directory path.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(base_dir):  # Check if the base directory doesn't exist\n",
    "        os.makedirs(base_dir)  # Create the base directory\n",
    "        return base_dir  # Return the base directory path\n",
    "    else:\n",
    "        counter = 2\n",
    "        while True:\n",
    "            new_dir = f\"{base_dir}{counter}\"  # Create a new directory path with a counter\n",
    "            if not os.path.exists(new_dir):  # Check if the new directory doesn't exist\n",
    "                os.makedirs(new_dir)  # Create the new directory\n",
    "                return new_dir  # Return the new directory path\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "base_output_dir = \"/cache/album/cache/kso-benjamin/bucket/kso/notebooks/test/predictions/seg-pred\"  # Define the base output directory\n",
    "output_dir = create_output_dir(base_output_dir)  # Create the output directory\n",
    "\n",
    "input_directory = \"/cache/album/cache/kso-benjamin/bucket/kso/notebooks/test/Seafloor_footage-1/Raw/\"  # Define the input directory\n",
    "\n",
    "for filename in os.listdir(input_directory):  # Iterate over the files in the input directory\n",
    "    filepath = os.path.join(input_directory, filename)  # Get the full path of the file\n",
    "\n",
    "    if filepath.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check if the file format is PNG, JPG, or JPEG\n",
    "\n",
    "        prediction = model.predict(filepath, confidence=30)  # Perform prediction on the image\n",
    "\n",
    "        prediction_data = prediction.json()  # Get the JSON results\n",
    "\n",
    "        csv_filename = os.path.splitext(filename)[0] + \"_prediction.csv\"  # Generate the CSV filename\n",
    "        csv_filepath = os.path.join(output_dir, csv_filename)  # Generate the CSV file path\n",
    "\n",
    "        with open(csv_filepath, mode='w', newline='') as csv_file:  # Open the CSV file for writing\n",
    "            csv_writer = csv.writer(csv_file)  # Create a CSV writer\n",
    "\n",
    "            header = [\"x\", \"y\", \"width\", \"height\", \"confidence\", \"class\", \"class_id\", \"detection_id\", \"image_path\", \"prediction_type\", \"points\", \"area\"]  # Define the header row\n",
    "            csv_writer.writerow(header)  # Write the header row to the CSV file\n",
    "\n",
    "            image_area = 0\n",
    "            quadrant_area = 0\n",
    "            rows = []\n",
    "            for idx, pred in enumerate(prediction_data['predictions']):  # Iterate over each prediction\n",
    "                mask_points = pred.get('points', [])  # Get the mask points\n",
    "\n",
    "                if mask_points:\n",
    "                    try:\n",
    "                        mask_points = [(float(point['x']), float(point['y'])) for point in mask_points]  # Convert mask points to float\n",
    "                        polygon = Polygon(mask_points)  # Create a polygon from the mask points\n",
    "                        area = polygon.area  # Calculate the area of the polygon\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error converting points to float for {filename}: {e}\")  # Print an error message\n",
    "                        area = 0\n",
    "                else:\n",
    "                    area = 0\n",
    "\n",
    "                if pred.get('class', '') == 'quadrant':  # Check if the prediction class is 'quadrant'\n",
    "                    x = float(pred.get('x', 0))\n",
    "                    y = float(pred.get('y', 0))\n",
    "                    width = float(pred.get('width', 0))\n",
    "                    height = float(pred.get('height', 0))\n",
    "                    quadrant_area = width * height  # Calculate the area of the quadrant\n",
    "\n",
    "                row = {\n",
    "                    \"x\": pred.get('x', ''),\n",
    "                    \"y\": pred.get('y', ''),\n",
    "                    \"width\": pred.get('width', ''),\n",
    "                    \"height\": pred.get('height', ''),\n",
    "                    \"confidence\": pred.get('confidence', ''),\n",
    "                    \"class\": pred.get('class', ''),\n",
    "                    \"class_id\": pred.get('class_id', ''),\n",
    "                    \"detection_id\": pred.get('detection_id', ''),\n",
    "                    \"image_path\": pred.get('image_path', ''),\n",
    "                    \"prediction_type\": pred.get('prediction_type', ''),\n",
    "                    \"points\": json.dumps(mask_points),  # Convert mask points to JSON string\n",
    "                    \"area\": area,\n",
    "                }\n",
    "                rows.append(row)  # Add the row to the list of rows\n",
    "\n",
    "            for row in rows:\n",
    "                csv_writer.writerow([\n",
    "                    row[\"x\"],\n",
    "                    row[\"y\"],\n",
    "                    row[\"width\"],\n",
    "                    row[\"height\"],\n",
    "                    row[\"confidence\"],\n",
    "                    row[\"class\"],\n",
    "                    row[\"class_id\"],\n",
    "                    row[\"detection_id\"],\n",
    "                    row[\"image_path\"],\n",
    "                    row[\"prediction_type\"],\n",
    "                    row[\"points\"],\n",
    "                    row[\"area\"]\n",
    "                ])  # Write each row to the CSV file\n",
    "\n",
    "        labeled_prediction = model.predict(filepath, confidence=30)  # Perform prediction with labels and save the result, set confidence threshold here.\n",
    "\n",
    "        output_image_path = os.path.join(output_dir, os.path.splitext(filename)[0] + \"_prediction.jpg\")  # Generate the output image path for labeled prediction\n",
    "\n",
    "        labeled_prediction.save(output_image_path)  # Save the labeled prediction result to an image file\n",
    "\n",
    "        display.clear_output()  # Clear the output\n",
    "\n",
    "def calculate_area_percentages(output_dir):\n",
    "    \"\"\"\n",
    "    Calculate the area percentages for each class in the output directory.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): The output directory path.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the results dictionary and the set of all classes.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    all_classes = set()\n",
    "\n",
    "    for filename in os.listdir(output_dir):  # Iterate over the files in the output directory\n",
    "        if filename.endswith('_prediction.csv'):  # Check if the file is a prediction CSV file\n",
    "            csv_filepath = os.path.join(output_dir, filename)  # Get the CSV file path\n",
    "            class_area_percentages = {}\n",
    "            total_quadrant_area = 0\n",
    "            total_image_area = 0\n",
    "            non_quadrant_detections = False\n",
    "\n",
    "            with open(csv_filepath, mode='r') as csv_file:  # Open the CSV file for reading\n",
    "                csv_reader = csv.DictReader(csv_file)  # Create a CSV reader\n",
    "                for row in csv_reader:  # Iterate over each row in the CSV file\n",
    "                    class_name = row['class']  # Get the class name\n",
    "\n",
    "                    if class_name == \"quadrant\":  # Check if the class is 'quadrant'\n",
    "                        width = float(row['width'])\n",
    "                        height = float(row['height'])\n",
    "                        total_quadrant_area = width * height  # Calculate the total quadrant area\n",
    "                        class_area_percentages[class_name] = total_quadrant_area\n",
    "                        all_classes.add(class_name)\n",
    "                        continue\n",
    "\n",
    "                    area = float(row.get('area', 0))  # Get the area\n",
    "\n",
    "                    if area > 0:\n",
    "                        non_quadrant_detections = True\n",
    "\n",
    "                    if class_name in class_area_percentages:\n",
    "                        class_area_percentages[class_name] += area\n",
    "                    else:\n",
    "                        class_area_percentages[class_name] = area\n",
    "                    all_classes.add(class_name)\n",
    "\n",
    "            image_name = filename.replace('_prediction.csv', '')  # Get the image name\n",
    "            results[image_name] = {}\n",
    "\n",
    "            if total_quadrant_area == 0:\n",
    "                image_path = os.path.join(input_directory, image_name + '.jpg')  # Get the image path\n",
    "                with Image.open(image_path) as img:  # Open the image\n",
    "                    total_image_area = img.width * img.height  # Calculate the total image area\n",
    "\n",
    "            if non_quadrant_detections:\n",
    "                for class_name, total_area in class_area_percentages.items():\n",
    "                    if class_name == \"quadrant\":\n",
    "                        results[image_name][class_name] = 100.0\n",
    "                    elif total_quadrant_area > 0:\n",
    "                        area_percentage = (total_area / total_quadrant_area) * 100  # Calculate the area percentage\n",
    "                        results[image_name][class_name] = area_percentage\n",
    "                    else:\n",
    "                        area_percentage = (total_area / total_image_area) * 100  # Calculate the area percentage\n",
    "                        results[image_name][class_name] = area_percentage\n",
    "            else:\n",
    "                results[image_name] = {'No detections besides the quadrant': 'Na'}\n",
    "\n",
    "    return results, all_classes\n",
    "\n",
    "def write_results_to_csv(results, all_classes, output_filepath):\n",
    "    \"\"\"\n",
    "    Write the results to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        results (dict): The results dictionary.\n",
    "        all_classes (set): The set of all classes.\n",
    "        output_filepath (str): The output CSV file path.\n",
    "    \"\"\"\n",
    "    formatted_results = {}\n",
    "    for image_name, class_areas in results.items():\n",
    "        formatted_results[image_name] = {class_name: class_areas.get(class_name, 'Na') for class_name in all_classes}\n",
    "\n",
    "    df = pd.DataFrame.from_dict(formatted_results, orient='index', columns=sorted(all_classes))\n",
    "    df.index.name = 'filename'\n",
    "    df.to_csv(output_filepath, na_rep='Na')\n",
    "\n",
    "results, all_classes = calculate_area_percentages(output_dir)  # Calculate the area percentages\n",
    "\n",
    "results_csv_filepath = os.path.join(output_dir, 'results.csv')  # Generate the results CSV file path\n",
    "write_results_to_csv(results, all_classes, results_csv_filepath)  # Write the results to a CSV file\n",
    "\n",
    "print(f'Results have been written to {results_csv_filepath}')  # Print a success message\n",
    "\n",
    "def getting_geolocation(output_dir):\n",
    "    \"\"\"\n",
    "    Get the geolocation information and generate a map.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): The output directory path.\n",
    "    \"\"\"\n",
    "    photos_koster_path = '/cache/album/cache/kso-benjamin/bucket/csv_Koster_Seafloor_Obs/photos_koster.csv'\n",
    "\n",
    "    photos_koster_df = pd.read_csv(photos_koster_path)  # Read the photos_koster.csv file\n",
    "    print(\"Columns in photos_koster_df:\", photos_koster_df.columns.tolist())\n",
    "    print(\"Sample filenames in photos_koster_df:\", photos_koster_df['filename'].head())\n",
    "\n",
    "    results_path = os.path.join(output_dir, 'results.csv')  # Generate the results CSV file path\n",
    "    results_df = pd.read_csv(results_path)  # Read the results.csv file\n",
    "    print(\"Columns in results_df:\", results_df.columns.tolist())\n",
    "    print(\"Sample filenames in results_df:\", results_df['filename'].head())\n",
    "\n",
    "    photos_koster_df = photos_koster_df.rename(columns={'PhotoPosition': 'PhotoPosition_koster'})  # Rename the 'PhotoPosition' column\n",
    "\n",
    "    if 'filename' not in photos_koster_df.columns or 'filename' not in results_df.columns:\n",
    "        raise KeyError(\"'filename' column not found in one of the CSV files\")  # Raise an error if 'filename' column is not found\n",
    "\n",
    "    photos_koster_df['filename'] = photos_koster_df['filename'].str.strip().str.lower()  # Strip and lowercase the filenames\n",
    "    results_df['filename'] = results_df['filename'].str.strip().str.lower()  # Strip and lowercase the filenames\n",
    "\n",
    "    results_df['filename'] = results_df['filename'].apply(lambda x: x if x.lower().endswith('.jpg') else x + '.jpg')  # Add '.jpg' extension to filenames if missing\n",
    "\n",
    "    merged_df = pd.merge(results_df, photos_koster_df[['filename', 'PhotoPosition_koster']], on='filename', how='left')  # Merge the results and photos_koster dataframes\n",
    "\n",
    "    missing_matches = merged_df[merged_df['PhotoPosition_koster'].isna()]  # Get the rows with missing matches\n",
    "    if not missing_matches.empty:\n",
    "        print(\"Filenames in results.csv with no matching PhotoPosition_koster:\")\n",
    "        print(missing_matches['filename'])\n",
    "\n",
    "    merged_df['PhotoPosition'] = merged_df['PhotoPosition_koster']  # Rename the 'PhotoPosition_koster' column to 'PhotoPosition'\n",
    "    merged_df = merged_df.drop(columns=['PhotoPosition_koster'])  # Drop the 'PhotoPosition_koster' column\n",
    "\n",
    "    merged_df.to_csv(results_path, index=False)  # Save the merged dataframe to the results.csv file\n",
    "\n",
    "    map_center = [58.0, 11.0]  # Define the map center\n",
    "    m = folium.Map(location=map_center, zoom_start=8)  # Create a folium map\n",
    "\n",
    "    for idx, row in merged_df.iterrows():  # Iterate over each row in the merged dataframe\n",
    "        if not pd.isna(row['PhotoPosition']):  # Check if the PhotoPosition is not NaN\n",
    "            lat, lon = map(float, row['PhotoPosition'].split(','))  # Split the PhotoPosition into latitude and longitude\n",
    "            color = 'green' if row['Seagrass'] else 'transparent'  # Set the color based on the presence of seagrass\n",
    "            popup_text = 'Seagrass present' if row['Seagrass'] else 'No seagrass'  # Set the popup text\n",
    "\n",
    "            folium.Rectangle(\n",
    "                bounds=[[lat-0.00007, lon-0.00007], [lat+0.00007, lon+0.00007]],  # Define the bounds of the rectangle\n",
    "                color='black',  # Set the outline color\n",
    "                fill=False,\n",
    "                fill_color=color,\n",
    "                fill_opacity=0.5 if row['Seagrass'] else 0,\n",
    "                tooltip=popup_text\n",
    "            ).add_to(m)  # Add the rectangle to the map\n",
    "\n",
    "    map_path = os.path.join(output_dir, 'seagrass_map.html')  # Generate the map file path\n",
    "    m.save(map_path)  # Save the map to an HTML file\n",
    "    print(f'Map saved to {map_path}')  # Print a success message\n",
    "\n",
    "getting_geolocation(output_dir)  # Call the getting_geolocation function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
