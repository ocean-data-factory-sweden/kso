{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hawaiian-ratio",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://panoptes-uploads.zooniverse.org/project_avatar/86c23ca7-bbaa-4e84-8d8a-876819551431.png\" type=\"image/png\" height=100 width=100>\n",
    "</img>\n",
    "<h1 align=\"right\">KSO Tutorials #6: Evaluate machine learning models</h1>\n",
    "<h3 align=\"right\">Written by the KSO Team</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-hamburg",
   "metadata": {},
   "source": [
    "# Set up KSO requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2bc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Install kso-object-detection and its requirements</font> { vertical-output: true }\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    import os\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Colab...\")\n",
    "\n",
    "    # Clone repo\n",
    "    !git clone --recurse-submodules https://github.com/ocean-data-factory-sweden/koster_yolov4.git\n",
    "    !pip install -q --upgrade pip\n",
    "    !pip install -qr koster_yolov4/requirements.txt\n",
    "    !pip install -qr koster_yolov4/yolov5_tracker/requirements.txt\n",
    "\n",
    "    # Fix libmagic issue\n",
    "    !apt-get -qq update && apt-get -qq install -y libmagic-dev > /dev/null\n",
    "\n",
    "    # Replace upsampling script with custom version\n",
    "    os.chdir(\"koster_yolov4/tutorials\")\n",
    "    !mv ../src/upsampling.py /usr/local/lib/python3.7/dist-packages/torch/nn/modules/upsampling.py\n",
    "\n",
    "    # Replace nearest neighbours script with custom version (due to relative path issue)\n",
    "    !cp ../src/multi_tracker_zoo.py ../yolov5_tracker/trackers/multi_tracker_zoo.py\n",
    "\n",
    "    # Add detection script for FRCNN model\n",
    "    !cp ../src/frcnn_detect.py ../yolov5/frcnn_detect.py\n",
    "\n",
    "    # Enable external widgets\n",
    "    from google.colab import output\n",
    "\n",
    "    output.enable_custom_widget_manager()\n",
    "\n",
    "    # Ensure widgets are shown properly\n",
    "    !jupyter nbextension enable --user --py widgetsnbextension\n",
    "    !jupyter nbextension enable --user --py jupyter_bbox_widget\n",
    "\n",
    "    print(\"All packages are installed and ready to go!\")\n",
    "    try:\n",
    "        clear_output()\n",
    "        print(\"All packages are installed and ready to go!\")\n",
    "    except:\n",
    "        clear_output()\n",
    "        print(\"There have been some issues installing the packages!\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    import sys\n",
    "    import pkgutil\n",
    "\n",
    "    if pkgutil.find_loader(\"torch\") is None:\n",
    "        !pip install -q --upgrade pip\n",
    "        !pip install -q torch==1.8.0 torchvision==0.12.0\n",
    "\n",
    "    # Replace nearest neighbours script with custom version (due to relative path issue)\n",
    "    !cp ../src/multi_tracker_zoo.py ../yolov5_tracker/trackers/multi_tracker_zoo.py\n",
    "    # Add detection script for FRCNN model\n",
    "    !cp ../src/frcnn_detect.py ../yolov5/frcnn_detect.py\n",
    "    # Ensure widgets are shown properly\n",
    "    !jupyter nbextension enable --user --py widgetsnbextension\n",
    "    !jupyter nbextension enable --user --py jupyter_bbox_widget\n",
    "    clear_output()\n",
    "    print(\"Running locally... you're good to go!\")\n",
    "\n",
    "#######Import Python packages########\n",
    "\n",
    "# Set the directory of the libraries\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Enables testing changes in utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Specify the path of the tutorials\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "# Set to display dataframes as interactive tables\n",
    "from itables import init_notebook_mode\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "\n",
    "# Import required modules\n",
    "import kso_utils.tutorials_utils as t_utils\n",
    "import kso_utils.project_utils as p_utils\n",
    "import kso_utils.server_utils as s_utils\n",
    "import kso_utils.t6_utils as t6\n",
    "import kso_utils.t5_utils as t5\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "clear_output()\n",
    "print(\"Packages loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Select the model type for evaluation</font> { vertical-output: true }\n",
    "model_type = t5.choose_model_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178cc9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-specific imports\n",
    "if model_type.value == 1:\n",
    "    import yolov5.detect as detect\n",
    "\n",
    "    print(\"Object detection model loaded\")\n",
    "elif model_type.value == 2:\n",
    "    import yolov5.classify.predict as detect\n",
    "\n",
    "    print(\"Image classification model loaded\")\n",
    "elif model_type.value == 3:\n",
    "    import yolov5.segment.predict as detect\n",
    "\n",
    "    print(\"Image segmentation model loaded\")\n",
    "elif model_type.value == 4:\n",
    "    import yolov5.frcnn_detect as detect\n",
    "\n",
    "    print(\"Faster RCNN model loaded\")\n",
    "else:\n",
    "    print(\"Invalid model specification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose your project</font> { vertical-output: true }\n",
    "project_name = t_utils.choose_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = t6.get_team_name(project_name.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = p_utils.find_project(project_name=project_name.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f913f",
   "metadata": {},
   "source": [
    "# Evaluate model on custom footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41909d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose the model</font> { vertical-output: true }\n",
    "model = t6.choose_model(project_name.value, team_name=team_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2456b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose folder to download the model</font> { vertical-output: true }\n",
    "download_dir = t_utils.choose_folder(\".\", \"where to download the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµážµážµ<i>Download model</font> { vertical-output: true }\n",
    "artifact_dir = t6.get_model(\n",
    "    model_name=model.value,\n",
    "    project_name=project_name.value,\n",
    "    download_path=download_dir.selected,\n",
    "    team_name=team_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµážµážµ<i>Choose your custom footage</font> { vertical-output: true }\n",
    "source = t_utils.choose_footage(\n",
    "    project,\n",
    "    project.movie_folder if project.movie_folder is not None else \".\",\n",
    "    \"custom footage\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d55f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_value = t_utils.process_source(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c4913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose folder where to save the runs</font> { vertical-output: true }\n",
    "# This should be left as default value in most cases.\n",
    "save_dir = t_utils.choose_folder(\".\", \"runs output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Start the run in Weights and Biases</font> { vertical-output: true }\n",
    "run = wandb.init(\n",
    "    entity=team_name,\n",
    "    project=\"model-evaluations\",\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b984ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose a confidence threshold for evaluation</font> { vertical-output: true }\n",
    "conf_thres = t6.choose_conf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Run model over selected custom footage</font> { vertical-output: true }\n",
    "detect.run(\n",
    "    weights=[\n",
    "        f\n",
    "        for f in Path(artifact_dir).iterdir()\n",
    "        if f.is_file() and str(f).endswith((\".pt\", \".model\")) and \"osnet\" not in str(f)\n",
    "    ][0],\n",
    "    source=source_value,\n",
    "    conf_thres=conf_thres.value,\n",
    "    save_txt=True,\n",
    "    save_conf=True,\n",
    "    project=save_dir.selected,\n",
    "    name=\"detect\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ce983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose folder with the evaluation data</font> { vertical-output: true }\n",
    "eval_dir = t_utils.choose_folder(\n",
    "    save_dir.selected if \"save_dir\" in vars() else \".\", \"runs output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24024c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = t6.set_config(conf_thres.value, model.value, eval_dir.selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Add the data to Weights and Biases</font> { vertical-output: true }\n",
    "t6.add_data_wandb(eval_dir.selected, \"detection_output\", run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54a6b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>View model output</font> { vertical-output: true }\n",
    "viewer = t6.choose_files(eval_dir.selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a2a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Investigate training and validation datasets (only image data)</font> { vertical-output: true }\n",
    "train_dataset, val_dataset = t6.get_dataset(project_name.value, model.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef76ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "t6.get_data_viewer(os.path.join(train_dataset, \"data/images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c6f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "t6.get_data_viewer(os.path.join(val_dataset, \"data/images\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da9e74f",
   "metadata": {},
   "source": [
    "# Track unique individuals (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb871ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_tracker = t6.track_objects(\n",
    "    source_dir=source_value,\n",
    "    artifact_dir=artifact_dir,\n",
    "    tracker_folder=eval_dir.selected,\n",
    "    conf_thres=conf_thres.value,\n",
    "    img_size=(540, 540),\n",
    "    gpu=True if torch.cuda.is_available() else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd15ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Add the data to Weights and Biases</font> { vertical-output: true }\n",
    "t6.add_data_wandb(Path(latest_tracker).parent.absolute(), \"tracker_output\", run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da59de",
   "metadata": {},
   "source": [
    "# Generate reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7448279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Generate classification report and counts by species</font> { vertical-output: true }\n",
    "# It requires Step 2\n",
    "csv_report = t6.generate_csv_report(eval_dir.selected, wandb_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041af685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Generate tracking report and counts by species</font> { vertical-output: true }\n",
    "# It requires Step 3\n",
    "tracking_report = t6.generate_counts(\n",
    "    eval_dir.selected, latest_tracker, artifact_dir, wandb_log=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c58523",
   "metadata": {},
   "source": [
    "ðŸ”´ <span style=\"color:red\">&nbsp;NOTE: Run this cell to complete WANDB run, OR else artifacts will not be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wildlife",
   "language": "python",
   "name": "wildlife"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f0064b85a3bc365415745ead9abb78ac240c43fe3a2a9861333bea64f4ce941"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
