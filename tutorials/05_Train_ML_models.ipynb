{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndyiMLRu0DKX"
   },
   "source": [
    "<img align=\"left\" src=\"https://panoptes-uploads.zooniverse.org/project_avatar/86c23ca7-bbaa-4e84-8d8a-876819551431.png\" type=\"image/png\" height=100 width=100>\n",
    "</img>\n",
    "<h1 align=\"right\">KSO Tutorials #5: Train ML models</h1>\n",
    "<h3 align=\"right\">Written by the KSO Team</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PSmaig62oa5"
   },
   "source": [
    "This notebook takes you through the process of importing a baseline model, training it on a dataset and evaluating the quality of the model. If you do not have a project with us yet, you can run the template project to get a taste of how it all works. \n",
    "\n",
    "ðŸ”´ <span style=\"color:red\">&nbsp;NOTE: In order to run this notebook, you need to have a Weights and Biases account. If you want to become a member of our Koster team on Weights and Biases, you may request this access by contacting jurie.germishuys@combine.se. But this is not necessary to run the template project. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnLWmifv0DKf"
   },
   "source": [
    "# Set up KSO requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBAYWXcp0DKi"
   },
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Install kso-object-detection and its requirements</font> { vertical-output: true }\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    import os\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Colab...\")\n",
    "\n",
    "    # Clone repo\n",
    "    !git clone --recurse-submodules https://github.com/ocean-data-factory-sweden/koster_yolov4.git\n",
    "    !pip install -q --upgrade pip\n",
    "    !pip install -qr koster_yolov4/requirements.txt\n",
    "    !pip install -qr koster_yolov4/yolov5_tracker/requirements.txt\n",
    "\n",
    "    # Fix libmagic issue\n",
    "    !apt-get -qq update && apt-get -qq install -y libmagic-dev > /dev/null\n",
    "\n",
    "    # Replace upsampling script with custom version\n",
    "    os.chdir(\"koster_yolov4/tutorials\")\n",
    "    !mv ../src/upsampling.py /usr/local/lib/python3.7/dist-packages/torch/nn/modules/upsampling.py\n",
    "\n",
    "    # Replace nearest neighbours script with custom version (due to relative path issue)\n",
    "    !cp ../src/multi_tracker_zoo.py ../yolov5_tracker/trackers/strong_sort/multi_tracker_zoo.py\n",
    "\n",
    "    # Enable external widgets\n",
    "    from google.colab import output\n",
    "\n",
    "    output.enable_custom_widget_manager()\n",
    "\n",
    "    # Ensure widgets are shown properly\n",
    "    !jupyter nbextension enable --user --py widgetsnbextension\n",
    "    !jupyter nbextension enable --user --py jupyter_bbox_widget\n",
    "\n",
    "    print(\"All packages are installed and ready to go!\")\n",
    "    try:\n",
    "        clear_output()\n",
    "        print(\"All packages are installed and ready to go!\")\n",
    "    except:\n",
    "        clear_output()\n",
    "        print(\"There have been some issues installing the packages!\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    import sys\n",
    "    import pkgutil\n",
    "\n",
    "    if pkgutil.find_loader(\"torch\") is None:\n",
    "        !pip install -q --upgrade pip\n",
    "        !pip install -q torch==1.8.0 torchvision==0.9.0\n",
    "\n",
    "    # Replace nearest neighbours script with custom version (due to relative path issue)\n",
    "    !cp ../src/multi_tracker_zoo.py ../yolov5_tracker/trackers/strong_sort/multi_tracker_zoo.py\n",
    "    # Ensure widgets are shown properly\n",
    "    !jupyter nbextension enable --user --py widgetsnbextension\n",
    "    !jupyter nbextension enable --user --py jupyter_bbox_widget\n",
    "    clear_output()\n",
    "    print(\"Running locally... you're good to go!\")\n",
    "\n",
    "#######Import Python packages########\n",
    "\n",
    "# Set the directory of the libraries\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Enables testing changes in utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Specify the path of the tutorials\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import required modules\n",
    "from ipyfilechooser import FileChooser\n",
    "import kso_utils.tutorials_utils as t_utils\n",
    "import kso_utils.project_utils as p_utils\n",
    "import kso_utils.server_utils as s_utils\n",
    "import kso_utils.t5_utils as t5\n",
    "import wandb\n",
    "\n",
    "print(\"Packages loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8x8PxQNI0UKI"
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# @title <font size=\"5\">â†“ ážµážµ<i>Select the model type for training</font> { vertical-output: true }\n",
    "model_type = t5.choose_model_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OpWW2mN0DKm"
   },
   "outputs": [],
   "source": [
    "# Model-specific imports\n",
    "if model_type.value == 1:\n",
    "    import yolov5.train as train\n",
    "    import yolov5.detect as detect\n",
    "    import yolov5.val as val\n",
    "\n",
    "    print(\"Object detection model loaded\")\n",
    "elif model_type.value == 2:\n",
    "    import yolov5.classify.train as train\n",
    "    import yolov5.classify.predict as detect\n",
    "    import yolov5.classify.val as val\n",
    "\n",
    "    print(\"Image classification model loaded\")\n",
    "elif model_type.value == 3:\n",
    "    import yolov5.segment.train as train\n",
    "    import yolov5.segment.predict as detect\n",
    "    import yolov5.segment.val as val\n",
    "\n",
    "    print(\"Image segmentation model loaded\")\n",
    "else:\n",
    "    print(\"Invalid model specification\")"
=======
    "# Set the directory of the libraries\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Enables testing changes in utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import required modules\n",
    "from pathlib import Path\n",
    "from ipyfilechooser import FileChooser\n",
    "import kso_utils.tutorials_utils as t_utils\n",
    "import kso_utils.project_utils as p_utils\n",
    "import kso_utils.server_utils as s_utils\n",
    "import kso_utils.t5_utils as t5\n",
    "from kso_utils.project import ProjectProcessor, MLProjectProcessor\n",
    "import wandb\n",
    "\n",
    "clear_output()\n",
    "print(\"Packages loaded successfully\")"
>>>>>>> 3e97084 (Update tutorials to reflect new project object structure)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZI0XH96WzfGs"
   },
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose your project</font> { vertical-output: true }\n",
    "project_name = t_utils.choose_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8ShAbg3zfGs"
   },
   "outputs": [],
   "source": [
    "# Save the name of the project\n",
    "project = p_utils.find_project(project_name=project_name.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate pp\n",
    "pp = ProjectProcessor(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate mlp\n",
    "mlp = MLProjectProcessor(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWaoapru0DKr"
   },
   "outputs": [],
   "source": [
    "# Only for Template Project (downloading prepared data)\n",
    "s_utils.get_ml_data(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcFpT7njzfGw"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Configure data paths</font> { vertical-output: true }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex5GT5Yh441Q"
   },
   "source": [
    "If you are running the Template project, the output_folder that you want to select is the ml-template-data. The path to this folder is printed in the cell above. For any other project, it is the folder where you have saved your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvaEo7mjzfGv"
   },
   "outputs": [],
   "source": [
    "# Specify path containing the images and labels folders.\n",
    "mlp.output_path = t_utils.choose_folder(\n",
    "    project.photo_folder if not project.photo_folder == \"None\" else \".\", \"output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "015UUPk20DKt"
   },
   "source": [
    "ðŸ”´ <span style=\"color:red\">&nbsp;NOTE: Each model type requires a specific folder structure to be in place. To be able to train your own Object Detection models, your data_path must contain a yml file for data and hyperparameters. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data#11-create-datasetyaml. For image classification models, there should be 3 folders (train, val, test) each containing images in class_name folders. For segmentation models, polygon coordinates are also required. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jt2PIFLdzfGw"
   },
   "outputs": [],
   "source": [
    "# Fix important paths\n",
    "mlp.setup_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XzclVxY70DKu"
   },
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose a suitable experiment name</font> { vertical-output: true }\n",
    "exp_name = t5.choose_experiment_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTb9DFFWzfGw"
   },
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose model to use for training</font> { vertical-output: true }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfQGfcMs5u1E"
   },
   "source": [
    "In the next cell you will specify the folder (can be any folder of choice) where you want to download the baseline model to, which you will select in the cell after. This baseline model will be used as the starting point for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDUZt0tf0DKu"
   },
   "outputs": [],
   "source": [
    "# Specify path to download baseline model\n",
    "download_folder = t_utils.choose_folder(\n",
    "    project.photo_folder if not project.photo_folder == \"None\" else \".\",\n",
    "    \"model download\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ovi-PKC60DKv"
   },
   "outputs": [],
   "source": [
    "weights = t5.choose_baseline_model(download_folder.selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose batch size and number of epochs for training</font> { vertical-output: true }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNQELgtzBQNR"
   },
   "source": [
    "The cell below will ask you which batch size and how many epochs you want to use during training. There are no strict rules for this and the best settings will depend on the choice of GPU and some randomness that we have encountered while training models. Therefore it will be some trial and error. As a starting point we advice to use a batch size of 8. For smaller datasets, we have experienced that 50-100 epochs has been sufficient to get good performance on the model (metrics that have reached a plateau), but to not overfit to the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBIYSeFH0DKv"
   },
   "outputs": [],
   "source": [
    "batch_size, epochs, img_h, img_w = mlp.choose_train_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43Um1iSVCG3u"
   },
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Give your WandB username, or team name</font> { vertical-output: true }\n",
    "# The runs will be sent to that WandB user or team\n",
    "# If you are part of the koster project, you can keep the default 'koster'.\n",
    "entity = mlp.choose_entity(alt_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# @title <font size=\"5\">â†“ ážµážµ<i>Train model with given configuration</font> { vertical-output: true }\n",
    "if model_type.value == 1:\n",
    "    train.run(\n",
    "        entity=entity.value,\n",
    "        data=data_path,\n",
    "        hyp=hyps_path,\n",
    "        weights=weights.artifact_path,\n",
    "        project=os.path.basename(project_path).replace(\" \", \"_\").lower(),\n",
    "        name=exp_name.value,\n",
    "        img_size=[720, 540],\n",
    "        batch_size=int(batch_size.value),\n",
    "        epochs=epochs.value,\n",
    "        workers=1,\n",
    "        single_cls=False,\n",
    "        cache_images=True,\n",
    "    )\n",
    "elif model_type.value == 2:\n",
    "    train.run(\n",
    "        entity=entity.value,\n",
    "        data=data_path,\n",
    "        model=weights.artifact_path,\n",
    "        project=os.path.basename(project_path).replace(\" \", \"_\").lower(),\n",
    "        name=exp_name.value,\n",
    "        img_size=224,\n",
    "        batch_size=int(batch_size.value),\n",
    "        epochs=epochs.value,\n",
    "        workers=1,\n",
    "    )\n",
    "else:\n",
    "    print(\"Segmentation model training not yet supported.\")"
=======
    "mlp.train_yolov5(\n",
    "    exp_name.value,\n",
    "    weights.artifact_path,\n",
    "    epochs=epochs.value,\n",
    "    batch_size=batch_size.value,\n",
    "    img_size=(img_h.value, img_w.value),\n",
    ")"
>>>>>>> 3e97084 (Update tutorials to reflect new project object structure)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRXru5arzfGw"
   },
   "source": [
    "# Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYD0QFv9D0Td"
   },
   "source": [
    "The model is now done with training. To see the loss, precision, recall and some other parameters per training epoch, click on the link in the previous cell. Here you can see your run in Weights and Biases. To evaluate the resulting model, please run the cells below. These execute the standard evaluation process from YOLO. \n",
    "\n",
    "For a biological evaluation of the model, please see Notebook 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3CI42sI0DKw"
   },
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose a confidence threshold</font> { vertical-output: true }\n",
    "conf_thres = t5.choose_eval_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Erw0xEw3zfGw"
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose the model to use for evaluation</font> { vertical-output: true }\n",
    "# The folder you want to select for eval_model is the folder with your experiment_name.\n",
    "eval_model = FileChooser(os.path.basename(project_path).replace(\" \", \"_\").lower())\n",
=======
    "# Choose model: The folder you want to select for eval_model is the folder with your experiment_name.\n",
    "eval_model = FileChooser(mlp.project_name)\n",
>>>>>>> 3e97084 (Update tutorials to reflect new project object structure)
    "display(eval_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j20Vv9JQaFcW"
   },
   "source": [
    "When you run the cell below, you will get some numbers logged on the screen, and 3 files that are stored in the folder 'your_experiment_name'_val. \n",
    "\n",
    "The numbers logged on the screen represent the following:\n",
    "* The first 7 numbers are the: mean precision, mean recal, mean average precision calculated at IOU threshold 0.5 (map@0.5), the mean average precision calculated at different IOU thresholds of 0.5-0.95 with steps of 0.05 (map@0.5:0.95) and then 3 training losses based on predicting the box, object or class. \n",
    "* The array gives the ap@0.5 per class.\n",
    "* The last 3 numbers are the same as the numbers that are already printed in a line above, where it says 'Speed: â€¦ ms per....' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Dx9tD3bzfGx"
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# @title <font size=\"5\">â†“ ážµážµ<i>Evaluate YOLO Model on Unseen Test data</font> { vertical-output: true }\n",
    "val.run(\n",
    "    data=data_path,\n",
    "    weights=tuned_weights,\n",
    "    conf_thres=conf_thres.value,\n",
    "    imgsz=640 if model_type.value == 1 else 224,\n",
    "    half=False,\n",
    "    project=os.path.basename(project_path).replace(\" \", \"_\").lower(),\n",
    "    name=str(exp_name.value) + \"_val\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWEcU4J2azW5"
   },
   "source": [
    "ðŸ”´ <span style=\"color:red\">&nbsp;NOTE: If you are not going to run the optional part 4 of this notebook, you should run the cell below to complete WANDB run, OR else artifacts will not be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vl9fJ0o7ayyf"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
=======
    "# Evaluate YOLO Model on Unseen Test data\n",
    "mlp.eval_yolov5(exp_name.value, eval_model.selected, conf_thres.value)"
>>>>>>> 3e97084 (Update tutorials to reflect new project object structure)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VGC_NMazfGx"
   },
   "source": [
    "# Enhance annotations using trained model (Optional) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aAs-KOU0DKx"
   },
   "source": [
    "Enhancement uses the trained model to increase the amount of annotations in the training data. This should only be done in cases where it is absolutely necessary as bad predictions lead to worse predictions when used to train the next iteration of the model. \n",
    "\n",
    "\n",
    "ðŸ”´ <span style=\"color:red\">&nbsp;NOTE: We recommend using a relatively high confidence threshold when enhancing trained models as low confidence predictions could significantly impact the quality of your annotated data. This is currently only available for object detection models.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeCPV09V0DKy"
   },
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose a confidence threshold</font> { vertical-output: true }\n",
    "eh_conf_thres = t5.choose_eval_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7kV7K2EzfGx"
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# @title <font size=\"5\">â†“ ážµážµ<i>Run the trained model on the entire dataset</font> { vertical-output: true }\n",
    "if model_type.value == 1:\n",
    "    detect.run(\n",
    "        weights=tuned_weights,\n",
    "        source=output_folder.selected + \"/images\",\n",
    "        imgsz=[640, 640],\n",
    "        conf_thres=eh_conf_thres.value,\n",
    "        save_txt=True,\n",
    "    )\n",
    "elif model_type.value == 2:\n",
    "    print(\"Enhancements not supported for image classification models at this time.\")\n",
    "else:\n",
    "    print(\"Enhancements not supported for segmentation models at this time.\")"
=======
    "mlp.enhance_yolov5(eh_conf_thres.value, img_size=[640, 640])"
>>>>>>> 3e97084 (Update tutorials to reflect new project object structure)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67uHzz1TzfGx"
   },
   "outputs": [],
   "source": [
    "# @title <font size=\"5\">â†“ ážµážµ<i>Choose run to use as enhanced annotations</font> { vertical-output: true }\n",
    "runs = FileChooser(\".\")\n",
    "display(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-sCJ8FZzfGx"
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# @title <font size=\"5\">â†“ ážµážµ<i>Move the new labels to the original label location</font> { vertical-output: true }\n",
    "runs = FileChooser(\".\")\n",
    "if model_type.value == 1:\n",
    "    !mv {output_folder}\"/labels\" {output_folder}\"/labels_org\"\n",
    "    !mv {runs.selected}\"/labels\" {output_folder}\"/labels\""
=======
    "# Move enhanced annotations to original run folder (NB: This will replace the original annotations)\n",
    "mlp.enhance_replace(runs.selected)"
>>>>>>> 3e97084 (Update tutorials to reflect new project object structure)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aw0uBxYV0DKy"
   },
   "source": [
    "#### Once you have moved the new labels to the original label location, you can return to Step 2 and train your model again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8umCRoDozfGx"
   },
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Train_YOLO_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "wildlife",
   "language": "python",
   "name": "wildlife"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.6"
=======
   "version": "3.8.8"
>>>>>>> 3e97084 (Update tutorials to reflect new project object structure)
  },
  "vscode": {
   "interpreter": {
    "hash": "9f0064b85a3bc365415745ead9abb78ac240c43fe3a2a9861333bea64f4ce941"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
